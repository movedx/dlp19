{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Programming Ex 02: Multi-Class SVM\n",
    "\n",
    "In this exercise you will:\n",
    "\n",
    "- Build the general architecture of a multi-class SVM, including:\n",
    "    - Calculating the cost function and its gradient\n",
    "    - Find the optimal hyperparameters by cross validation\n",
    "\n",
    "Instruction:\n",
    "\n",
    "- Run each cell and read the comments carefully (in the right order)\n",
    "- Implement the missing codes that are required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Required Libraries [0pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from utils.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10 load data [0pt]\n",
    "\n",
    "Run the next cell to define a data helper function that does some basic preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3073)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3073)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000, 3073)\n",
      "Test labels shape:  (1000,)\n",
      "dev data shape:  (500, 3073)\n",
      "dev labels shape:  (500,)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier. These are the same steps as we used for the\n",
    "    SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = '../../data/cifar/'\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "    \n",
    "    # subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "    X_dev = X_train[mask]\n",
    "    y_dev = y_train[mask]\n",
    "    \n",
    "    # Preprocessing: reshape the image data into rows\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "    \n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis = 0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_dev -= mean_image\n",
    "    \n",
    "    # add bias dimension and transform into columns\n",
    "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)\n",
    "print('dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Multi-Class SVM - Loss Function and Gradients [5pt]\n",
    "\n",
    "Complete the implementation of svm_loss_naive by implementing a naive analytical gradient descent that uses nested loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_loss_naive(W, X, y, reg):\n",
    "    \"\"\"\n",
    "    Structured SVM loss function, naive implementation (with loops).\n",
    "\n",
    "    Inputs have dimension D, there are C classes, and we operate on minibatches\n",
    "    of N examples.\n",
    "\n",
    "    Inputs:\n",
    "    - W: A numpy array of shape (D, C) containing weights.\n",
    "    - X: A numpy array of shape (N, D) containing a minibatch of data.\n",
    "    - y: A numpy array of shape (N,) containing training labels; y[i] = c means\n",
    "         that X[i] has label c, where 0 <= c < C.\n",
    "    - reg: (float) regularization strength\n",
    "\n",
    "    Returns a tuple of:\n",
    "    - loss as single float\n",
    "    - gradient with respect to weights W; an array of same shape as W\n",
    "    \"\"\"\n",
    "    dW = np.zeros(W.shape) # initialize the gradient as zero\n",
    "    num_classes = W.shape[1]\n",
    "    num_samples = X.shape[0]\n",
    "\n",
    "    #############################################################################\n",
    "    # TODO: Compute the multi-class svm loss and its gradient using explicit    #\n",
    "    # loops. Store the loss in loss and the gradient in dW. Don't forget the    #\n",
    "    # regularization!                                                           #\n",
    "    #############################################################################\n",
    "    \n",
    "    loss = 0.0\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        scores = X[i].dot(W)\n",
    "        scores -= np.max(scores)\n",
    "        correct_class_score = scores[y[i]]\n",
    "        for j in range(num_classes):\n",
    "            if j == y[i]:\n",
    "                continue\n",
    "            margin = scores[j] - correct_class_score + 1 #delta = 1\n",
    "            if margin >= 0:\n",
    "                loss += margin\n",
    "                dW[:,y[i]] -= X[i,:]\n",
    "                dW[:,j] += X[i,:]\n",
    "                \n",
    "    loss /= num_samples\n",
    "    loss += reg * np.sum(W * W) #L2\n",
    "    dW /= num_samples\n",
    "    dW += reg * 2 * W\n",
    "    \n",
    "    #############################################################################\n",
    "    #                         END OF YOUR CODE                                  #\n",
    "    #############################################################################\n",
    "    return loss, dW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check: Gradients [0pt] \n",
    "\n",
    "The next cell is a self-check for you to make sure your SVM implementation works!\n",
    "It compares your analytical gradients to numerically calculated gradients.\n",
    "The numerical and analytical values should be the same up to printing accurracy,\n",
    "relative error should be smaller than $10^{-7}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: -9.199311,\tanalytic: -9.199311,\trelative error: 1.014936e-11\n",
      "numerical: 5.588034,\tanalytic: 5.588034,\trelative error: 2.864922e-11\n",
      "numerical: 2.678441,\tanalytic: 2.678441,\trelative error: 2.404502e-11\n",
      "numerical: -0.204936,\tanalytic: -0.204936,\trelative error: 1.005308e-10\n",
      "numerical: 34.632831,\tanalytic: 34.632831,\trelative error: 9.127153e-12\n",
      "numerical: -4.543186,\tanalytic: -4.543186,\trelative error: 5.459327e-11\n",
      "numerical: -15.803539,\tanalytic: -15.803539,\trelative error: 1.823320e-11\n",
      "numerical: 7.250411,\tanalytic: 7.250411,\trelative error: 5.070985e-11\n",
      "numerical: -6.056487,\tanalytic: -6.056487,\trelative error: 3.983004e-11\n",
      "numerical: 9.078687,\tanalytic: 9.078687,\trelative error: 1.688419e-11\n",
      "numerical: 21.747110,\tanalytic: 21.747110,\trelative error: 1.316566e-11\n",
      "numerical: 15.075767,\tanalytic: 15.075767,\trelative error: 3.121522e-11\n",
      "numerical: 4.694691,\tanalytic: 4.694691,\trelative error: 7.884686e-12\n",
      "numerical: 17.814966,\tanalytic: 17.814966,\trelative error: 6.788358e-13\n",
      "numerical: 24.325933,\tanalytic: 24.325933,\trelative error: 2.533612e-12\n",
      "numerical: 5.413714,\tanalytic: 5.413714,\trelative error: 1.738298e-11\n",
      "numerical: 23.289822,\tanalytic: 23.289822,\trelative error: 7.733580e-12\n",
      "numerical: 16.531305,\tanalytic: 16.531305,\trelative error: 2.338406e-11\n",
      "numerical: -9.297887,\tanalytic: -9.297887,\trelative error: 8.494224e-11\n",
      "numerical: 16.749282,\tanalytic: 16.749282,\trelative error: 2.013467e-12\n"
     ]
    }
   ],
   "source": [
    "# Compute the loss and its gradient at W.\n",
    "W = np.random.randn(3073, 10) * 0.0001 \n",
    "loss, grad = svm_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# Numerically compute the gradient along several randomly chosen dimensions, and\n",
    "# compare them with your analytically computed gradient. The numbers should match\n",
    "# almost exactly along all dimensions.\n",
    "from utils.gradient_check import grad_check_sparse\n",
    "f = lambda w: svm_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad)\n",
    "\n",
    "# do the gradient check once again with regularization turned on\n",
    "# you didn't forget the regularization gradient did you?\n",
    "loss, grad = svm_loss_naive(W, X_dev, y_dev, 5e1)\n",
    "f = lambda w: svm_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Multi-Class SVM [5pt]\n",
    "\n",
    "Implement a vectorized version of the SVM loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_loss_vectorized(W, X, y, reg):\n",
    "    \"\"\"\n",
    "    Structured SVM loss function, vectorized implementation.\n",
    "\n",
    "    Inputs and outputs are the same as svm_loss_naive.\n",
    "    \"\"\"\n",
    "    loss = 0.0\n",
    "    dW = np.zeros(W.shape) # initialize the gradient as zero\n",
    "\n",
    "    #############################################################################\n",
    "    # TODO:                                                                     #\n",
    "    # Implement a vectorized version of the structured SVM loss, storing the    #\n",
    "    # result in loss.                                                           #\n",
    "    #############################################################################\n",
    "    \n",
    "    num_samples = X.shape[0]\n",
    "    delta = 1\n",
    "\n",
    "    scores = X.dot(W)\n",
    "    scores -= np.max(scores, axis=1, keepdims=True)\n",
    "    correct_class_score = scores[np.arange(num_samples), y]\n",
    "    margins = np.maximum(0, scores - correct_class_score[:,np.newaxis] + delta)\n",
    "    margins[np.arange(num_samples), y] = 0\n",
    "    loss = np.sum(margins)\n",
    "    \n",
    "    loss /= num_samples\n",
    "    loss += reg * np.sum(W * W)\n",
    "        \n",
    "    \n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################\n",
    "\n",
    "\n",
    "    #############################################################################\n",
    "    # TODO:                                                                     #\n",
    "    # Implement a vectorized version of the gradient for the structured SVM     #\n",
    "    # loss, storing the result in dW.                                           #\n",
    "    #                                                                           #\n",
    "    # Hint: Instead of computing the gradient from scratch, it may be easier    #\n",
    "    # to reuse some of the intermediate values that you used to compute the     #\n",
    "    # loss.                                                                     #\n",
    "    #############################################################################\n",
    "\n",
    "    X_mask = np.zeros(margins.shape)\n",
    "    X_mask[margins > 0] = 1\n",
    "    \n",
    "    count = np.sum(X_mask, axis=1)\n",
    "    X_mask[np.arange(num_samples), y] = -count\n",
    "    \n",
    "    dW = X.T.dot(X_mask)\n",
    "    \n",
    "    dW /= num_samples\n",
    "    dW += reg * 2 * W\n",
    "    \n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################\n",
    "\n",
    "    return loss, dW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check: Performance Comparison [0pt]\n",
    "\n",
    "Execute the cell below to run a performance comparison between the naive implementation using loops\n",
    "and the optimized version using vectorized instructions.\n",
    "The two versions should compute the same results, but the vectorized version should be much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive loss: 8.713257e+00 computed in -0.155902s\n",
      "Vectorized loss: 8.713257e+00 computed in -0.003999s\n",
      "Loss difference: 0.000000\n",
      "Gradient difference: 0.000000\n",
      "Runtime abs. difference: 0.151902 seconds\n",
      "Runtime rel. improvement: 0.974346 percent\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "loss_naive, grad_naive = svm_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "diff = tic - toc\n",
    "print('Naive loss: %e computed in %fs' % (loss_naive, diff))\n",
    "\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = svm_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "diff_vec = tic - toc\n",
    "print('Vectorized loss: %e computed in %fs' % (loss_vectorized, diff_vec))\n",
    "\n",
    "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
    "# of the gradient.\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
    "print('Gradient difference: %f' % grad_difference)\n",
    "print('Runtime abs. difference: %f seconds' % (diff_vec - diff))\n",
    "print('Runtime rel. improvement: %f percent' % (1 - (diff_vec / diff)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent [0pt]\n",
    "\n",
    "You already implemented this in the last exercise. Please run the cell below to define this function in the current namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train multi-class svm by SGD, implemented in last assignment\n",
    "def train_SGD(X, y, learning_rate=1e-3, reg=1e-5, num_iters=100,\n",
    "            batch_size=200, verbose=False):\n",
    "    \"\"\"\n",
    "    Train this linear classifier using stochastic gradient descent.\n",
    "\n",
    "    Inputs:\n",
    "    - X: A numpy array of shape (N, D) containing training data; there are N\n",
    "      training samples each of dimension D.\n",
    "    - y: A numpy array of shape (N,) containing training labels; y[i] = c\n",
    "      means that X[i] has label 0 <= c < C for C classes.\n",
    "    - learning_rate: (float) learning rate for optimization.\n",
    "    - reg: (float) regularization strength.\n",
    "    - num_iters: (integer) number of steps to take when optimizing\n",
    "    - batch_size: (integer) number of training examples to use at each step.\n",
    "    - verbose: (boolean) If true, print progress during optimization.\n",
    "\n",
    "    Outputs:\n",
    "    W: A numpy array of shape (D, C) containing weights\n",
    "    loss_history: A list containing the value of the loss function at each training iteration.\n",
    "    \"\"\"\n",
    "    num_train, dim = X.shape\n",
    "    num_classes = np.max(y) + 1 # assume y takes values 0...K-1 where K is number of classes\n",
    "   \n",
    "    # Generate a random softmax weight matrix\n",
    "    W = 0.001 * np.random.randn(dim, num_classes)\n",
    "\n",
    "    # Run stochastic gradient descent to optimize W\n",
    "    loss_history = []\n",
    "    for it in range(num_iters):\n",
    "        X_batch = None\n",
    "        y_batch = None\n",
    "        p = np.random.choice(num_train, batch_size)\n",
    "        X_batch = X[p,:]\n",
    "        y_batch = y[p]\n",
    "  \n",
    "\n",
    "        # evaluate loss and gradient\n",
    "        loss, grad = svm_loss_vectorized(W,X_batch, y_batch, reg)\n",
    "        loss_history.append(loss)\n",
    " \n",
    "        W -= learning_rate*grad\n",
    "\n",
    "        if verbose and it % 100 == 0:\n",
    "            print('iteration %d / %d: loss %f' % (it, num_iters, loss))\n",
    "\n",
    "    return W, loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Training [0pt]\n",
    "\n",
    "Run the next cell to train a SVM classifier using stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 1500: loss 781.347135\n",
      "iteration 100 / 1500: loss 284.974490\n",
      "iteration 200 / 1500: loss 107.594259\n",
      "iteration 300 / 1500: loss 42.679354\n",
      "iteration 400 / 1500: loss 19.201278\n",
      "iteration 500 / 1500: loss 10.773879\n",
      "iteration 600 / 1500: loss 7.521512\n",
      "iteration 700 / 1500: loss 6.102791\n",
      "iteration 800 / 1500: loss 5.909989\n",
      "iteration 900 / 1500: loss 5.600303\n",
      "iteration 1000 / 1500: loss 5.000242\n",
      "iteration 1100 / 1500: loss 5.461392\n",
      "iteration 1200 / 1500: loss 5.571597\n",
      "iteration 1300 / 1500: loss 5.439947\n",
      "iteration 1400 / 1500: loss 5.852615\n",
      "This took 7.831156s\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "W, loss_hist = train_SGD(X_train, y_train, learning_rate=1e-7, reg=2.5e4,\n",
    "                      num_iters=1500, verbose=True)\n",
    "toc = time.time()\n",
    "print('This took %fs' % (toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check: Prediction [0pt]\n",
    "\n",
    "The next two cells define and run the predict function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(W, X):\n",
    "    \"\"\"\n",
    "    Use the trained weights of this linear classifier to predict labels for\n",
    "    data points.\n",
    "\n",
    "    Inputs:\n",
    "    - W: A numpy array of shape (D, C) containing weights\n",
    "    - X: A numpy array of shape (N, D) containing training data; there are N\n",
    "      training samples each of dimension D.\n",
    "\n",
    "    Returns:\n",
    "    - y_pred: Predicted labels for the data in X. y_pred is a 1-dimensional\n",
    "      array of length N, and each element is an integer giving the predicted\n",
    "      class.\n",
    "    \"\"\"\n",
    "    y_pred = np.zeros(X.shape[0])\n",
    "    y_pred = np.argmax(np.dot(X,W), axis=1)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.370163\n",
      "validation accuracy: 0.378000\n"
     ]
    }
   ],
   "source": [
    "# Write the predict function and evaluate the performance on both the\n",
    "# training and validation set\n",
    "y_train_pred = predict(W,X_train)\n",
    "print('training accuracy: %f' % np.mean(y_train == y_train_pred))\n",
    "y_val_pred = predict(W,X_val)\n",
    "print('validation accuracy: %f' % np.mean(y_val == y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Hyperparameter Tuning [5pt]\n",
    "\n",
    "Follow the instructions in the comments and run a hyperparameter tuning adapted to a SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 3000: loss 792.962234\n",
      "iteration 100 / 3000: loss 288.322797\n",
      "iteration 200 / 3000: loss 108.304618\n",
      "iteration 300 / 3000: loss 42.229442\n",
      "iteration 400 / 3000: loss 18.377284\n",
      "iteration 500 / 3000: loss 10.290033\n",
      "iteration 600 / 3000: loss 6.488134\n",
      "iteration 700 / 3000: loss 6.118766\n",
      "iteration 800 / 3000: loss 5.572720\n",
      "iteration 900 / 3000: loss 5.125654\n",
      "iteration 1000 / 3000: loss 5.315388\n",
      "iteration 1100 / 3000: loss 4.839508\n",
      "iteration 1200 / 3000: loss 5.150881\n",
      "iteration 1300 / 3000: loss 5.119617\n",
      "iteration 1400 / 3000: loss 5.460648\n",
      "iteration 1500 / 3000: loss 5.567030\n",
      "iteration 1600 / 3000: loss 5.607835\n",
      "iteration 1700 / 3000: loss 5.189786\n",
      "iteration 1800 / 3000: loss 5.073531\n",
      "iteration 1900 / 3000: loss 5.292860\n",
      "iteration 2000 / 3000: loss 5.403979\n",
      "iteration 2100 / 3000: loss 5.330771\n",
      "iteration 2200 / 3000: loss 5.629805\n",
      "iteration 2300 / 3000: loss 5.605106\n",
      "iteration 2400 / 3000: loss 5.472692\n",
      "iteration 2500 / 3000: loss 5.735871\n",
      "iteration 2600 / 3000: loss 5.344353\n",
      "iteration 2700 / 3000: loss 5.289458\n",
      "iteration 2800 / 3000: loss 4.780842\n",
      "iteration 2900 / 3000: loss 4.906003\n",
      "iteration 0 / 3000: loss 1555.276092\n",
      "iteration 100 / 3000: loss 210.269103\n",
      "iteration 200 / 3000: loss 32.873318\n",
      "iteration 300 / 3000: loss 8.850776\n",
      "iteration 400 / 3000: loss 6.087756\n",
      "iteration 500 / 3000: loss 5.587100\n",
      "iteration 600 / 3000: loss 5.875095\n",
      "iteration 700 / 3000: loss 5.918148\n",
      "iteration 800 / 3000: loss 5.663049\n",
      "iteration 900 / 3000: loss 5.365673\n",
      "iteration 1000 / 3000: loss 5.852658\n",
      "iteration 1100 / 3000: loss 5.893367\n",
      "iteration 1200 / 3000: loss 5.066538\n",
      "iteration 1300 / 3000: loss 5.749730\n",
      "iteration 1400 / 3000: loss 6.140121\n",
      "iteration 1500 / 3000: loss 5.508284\n",
      "iteration 1600 / 3000: loss 6.174848\n",
      "iteration 1700 / 3000: loss 6.073229\n",
      "iteration 1800 / 3000: loss 5.866248\n",
      "iteration 1900 / 3000: loss 5.984664\n",
      "iteration 2000 / 3000: loss 5.190943\n",
      "iteration 2100 / 3000: loss 5.878215\n",
      "iteration 2200 / 3000: loss 5.463956\n",
      "iteration 2300 / 3000: loss 5.083622\n",
      "iteration 2400 / 3000: loss 5.306922\n",
      "iteration 2500 / 3000: loss 5.463888\n",
      "iteration 2600 / 3000: loss 5.497205\n",
      "iteration 2700 / 3000: loss 5.545342\n",
      "iteration 2800 / 3000: loss 6.097731\n",
      "iteration 2900 / 3000: loss 5.633475\n",
      "iteration 0 / 3000: loss 796.260713\n",
      "iteration 100 / 3000: loss 473.687861\n",
      "iteration 200 / 3000: loss 288.862884\n",
      "iteration 300 / 3000: loss 177.100679\n",
      "iteration 400 / 3000: loss 108.442827\n",
      "iteration 500 / 3000: loss 68.001890\n",
      "iteration 600 / 3000: loss 43.010429\n",
      "iteration 700 / 3000: loss 28.078445\n",
      "iteration 800 / 3000: loss 18.691437\n",
      "iteration 900 / 3000: loss 13.420964\n",
      "iteration 1000 / 3000: loss 10.068510\n",
      "iteration 1100 / 3000: loss 7.564511\n",
      "iteration 1200 / 3000: loss 7.163859\n",
      "iteration 1300 / 3000: loss 6.605959\n",
      "iteration 1400 / 3000: loss 5.920349\n",
      "iteration 1500 / 3000: loss 6.212817\n",
      "iteration 1600 / 3000: loss 5.845929\n",
      "iteration 1700 / 3000: loss 5.086134\n",
      "iteration 1800 / 3000: loss 5.183609\n",
      "iteration 1900 / 3000: loss 5.392354\n",
      "iteration 2000 / 3000: loss 5.172936\n",
      "iteration 2100 / 3000: loss 5.166880\n",
      "iteration 2200 / 3000: loss 5.084877\n",
      "iteration 2300 / 3000: loss 5.139677\n",
      "iteration 2400 / 3000: loss 5.176357\n",
      "iteration 2500 / 3000: loss 5.445866\n",
      "iteration 2600 / 3000: loss 5.060686\n",
      "iteration 2700 / 3000: loss 5.723829\n",
      "iteration 2800 / 3000: loss 5.329374\n",
      "iteration 2900 / 3000: loss 5.010517\n",
      "iteration 0 / 3000: loss 1556.754493\n",
      "iteration 100 / 3000: loss 568.219405\n",
      "iteration 200 / 3000: loss 211.266405\n",
      "iteration 300 / 3000: loss 81.247524\n",
      "iteration 400 / 3000: loss 32.864993\n",
      "iteration 500 / 3000: loss 15.624477\n",
      "iteration 600 / 3000: loss 9.046633\n",
      "iteration 700 / 3000: loss 7.562433\n",
      "iteration 800 / 3000: loss 5.943950\n",
      "iteration 900 / 3000: loss 5.743494\n",
      "iteration 1000 / 3000: loss 5.628273\n",
      "iteration 1100 / 3000: loss 5.359636\n",
      "iteration 1200 / 3000: loss 5.938411\n",
      "iteration 1300 / 3000: loss 5.873044\n",
      "iteration 1400 / 3000: loss 5.523498\n",
      "iteration 1500 / 3000: loss 5.745937\n",
      "iteration 1600 / 3000: loss 5.583290\n",
      "iteration 1700 / 3000: loss 5.902752\n",
      "iteration 1800 / 3000: loss 5.256055\n",
      "iteration 1900 / 3000: loss 6.034968\n",
      "iteration 2000 / 3000: loss 5.758408\n",
      "iteration 2100 / 3000: loss 5.813956\n",
      "iteration 2200 / 3000: loss 5.657123\n",
      "iteration 2300 / 3000: loss 6.108606\n",
      "iteration 2400 / 3000: loss 5.270535\n",
      "iteration 2500 / 3000: loss 5.712706\n",
      "iteration 2600 / 3000: loss 5.569236\n",
      "iteration 2700 / 3000: loss 6.037517\n",
      "iteration 2800 / 3000: loss 5.720667\n",
      "iteration 2900 / 3000: loss 5.739607\n",
      "iteration 0 / 3000: loss 793.590502\n",
      "iteration 100 / 3000: loss 714.154069\n",
      "iteration 200 / 3000: loss 643.768448\n",
      "iteration 300 / 3000: loss 584.562265\n",
      "iteration 400 / 3000: loss 528.559487\n",
      "iteration 500 / 3000: loss 477.908208\n",
      "iteration 600 / 3000: loss 431.009064\n",
      "iteration 700 / 3000: loss 390.397885\n",
      "iteration 800 / 3000: loss 354.358675\n",
      "iteration 900 / 3000: loss 321.197529\n",
      "iteration 1000 / 3000: loss 289.781042\n",
      "iteration 1100 / 3000: loss 264.224768\n",
      "iteration 1200 / 3000: loss 238.782208\n",
      "iteration 1300 / 3000: loss 215.826057\n",
      "iteration 1400 / 3000: loss 195.575755\n",
      "iteration 1500 / 3000: loss 177.295773\n",
      "iteration 1600 / 3000: loss 160.324218\n",
      "iteration 1700 / 3000: loss 145.237491\n",
      "iteration 1800 / 3000: loss 132.271395\n",
      "iteration 1900 / 3000: loss 119.542806\n",
      "iteration 2000 / 3000: loss 109.022289\n",
      "iteration 2100 / 3000: loss 98.850115\n",
      "iteration 2200 / 3000: loss 90.282408\n",
      "iteration 2300 / 3000: loss 81.765110\n",
      "iteration 2400 / 3000: loss 74.925027\n",
      "iteration 2500 / 3000: loss 68.406286\n",
      "iteration 2600 / 3000: loss 62.129169\n",
      "iteration 2700 / 3000: loss 56.600158\n",
      "iteration 2800 / 3000: loss 51.491344\n",
      "iteration 2900 / 3000: loss 47.235297\n",
      "iteration 0 / 3000: loss 1557.122177\n",
      "iteration 100 / 3000: loss 1269.493977\n",
      "iteration 200 / 3000: loss 1039.736126\n",
      "iteration 300 / 3000: loss 851.667045\n",
      "iteration 400 / 3000: loss 698.993278\n",
      "iteration 500 / 3000: loss 571.265887\n",
      "iteration 600 / 3000: loss 467.967011\n",
      "iteration 700 / 3000: loss 384.000409\n",
      "iteration 800 / 3000: loss 314.700037\n",
      "iteration 900 / 3000: loss 258.703453\n",
      "iteration 1000 / 3000: loss 212.310300\n",
      "iteration 1100 / 3000: loss 174.768387\n",
      "iteration 1200 / 3000: loss 143.666916\n",
      "iteration 1300 / 3000: loss 118.711094\n",
      "iteration 1400 / 3000: loss 98.188806\n",
      "iteration 1500 / 3000: loss 81.370300\n",
      "iteration 1600 / 3000: loss 67.619653\n",
      "iteration 1700 / 3000: loss 56.111825\n",
      "iteration 1800 / 3000: loss 47.291221\n",
      "iteration 1900 / 3000: loss 39.283675\n",
      "iteration 2000 / 3000: loss 33.618293\n",
      "iteration 2100 / 3000: loss 28.331333\n",
      "iteration 2200 / 3000: loss 23.789069\n",
      "iteration 2300 / 3000: loss 21.000089\n",
      "iteration 2400 / 3000: loss 17.860542\n",
      "iteration 2500 / 3000: loss 15.747861\n",
      "iteration 2600 / 3000: loss 13.371038\n",
      "iteration 2700 / 3000: loss 12.164628\n",
      "iteration 2800 / 3000: loss 11.180042\n",
      "iteration 2900 / 3000: loss 9.730778\n",
      "lr 1.000000e-08 reg 2.500000e+04 train accuracy: 0.324245 val accuracy: 0.347000\n",
      "lr 1.000000e-08 reg 5.000000e+04 train accuracy: 0.356204 val accuracy: 0.365000\n",
      "lr 5.000000e-08 reg 2.500000e+04 train accuracy: 0.374306 val accuracy: 0.390000\n",
      "lr 5.000000e-08 reg 5.000000e+04 train accuracy: 0.365837 val accuracy: 0.379000\n",
      "lr 1.000000e-07 reg 2.500000e+04 train accuracy: 0.362714 val accuracy: 0.377000\n",
      "lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.352653 val accuracy: 0.359000\n",
      "best validation accuracy achieved during cross-validation: 0.390000\n"
     ]
    }
   ],
   "source": [
    "# Use the validation set to tune hyperparameters (regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful you should be able to\n",
    "# get a classification accuracy of about 0.4 on the validation set.\n",
    "learning_rates = [1e-7, 5e-8, 1e-8]\n",
    "regularization_strengths = [2.5e4, 5e4]\n",
    "\n",
    "# results is dictionary mapping tuples of the form\n",
    "# (learning_rate, regularization_strength) to tuples of the form\n",
    "# (training_accuracy, validation_accuracy). The accuracy is simply the fraction\n",
    "# of data points that are correctly classified.\n",
    "results = {}\n",
    "best_val = -1   # The highest validation accuracy that we have seen so far.\n",
    "best_W = None # The LinearSVM object that achieved the highest validation rate.\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Write code that chooses the best hyperparameters by tuning on the validation #\n",
    "# set. For each combination of hyperparameters, train a linear SVM on the      #\n",
    "# training set, compute its accuracy on the training and validation sets, and  #\n",
    "# store these numbers in the results dictionary. In addition, store the best   #\n",
    "# validation accuracy in best_val and the LinearSVM object that achieves this  #\n",
    "# accuracy in best_svm.                                                        #\n",
    "#                                                                              #\n",
    "# Hint: You should use a small value for num_iters as you develop your         #\n",
    "# validation code so that the SVMs don't take much time to train; once you are #\n",
    "# confident that your validation code works, you should rerun the validation   #\n",
    "# code with a larger value for num_iters.                                      #\n",
    "################################################################################\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for rs in regularization_strengths:\n",
    "        W, _ = train_SGD(X_train, y_train, learning_rate=lr, reg=rs, num_iters=3000, verbose=True)\n",
    "        y_train_pred = predict(W, X_train)\n",
    "        training_accuracy = np.mean(y_train == y_train_pred)\n",
    "        y_val_pred = predict(W, X_val)\n",
    "        validation_accuracy = np.mean(y_val == y_val_pred)\n",
    "        results[(lr, rs)] = (training_accuracy, validation_accuracy)\n",
    "        if max(results.values())[1] > best_val:\n",
    "            best_val = max(results.values())[1]\n",
    "            best_W = W\n",
    "\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "    \n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check: Test Accuracy and Weight Visualization [0pt]\n",
    "\n",
    "Run the next cell to try your SVM implementation on unseen test data. Accuracy should be around 0.35.\n",
    "The last cell displays the (rescaled) weights your SVM has learned for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear SVM on raw pixels final test set accuracy: 0.375000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best svm on test set\n",
    "y_test_pred = predict(best_W,X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('linear SVM on raw pixels final test set accuracy: %f' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17100f1acc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the learned weights for each class.\n",
    "# Depending on your choice of learning rate and regularization strength, these may\n",
    "# or may not be nice to look at.\n",
    "w = best_W[:-1,:] # strip out the bias\n",
    "w = w.reshape(32, 32, 3, 10)\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "      \n",
    "    # Rescale the weights to be between 0 and 255\n",
    "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "    plt.imshow(wimg.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.title(classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
